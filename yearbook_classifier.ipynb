{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajat/Box Sync/ImpGAN/pytorch_CelebAToYearbook_cDCGAN.py:3: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 126, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-8be484e43f72>\", line 8, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "from pytorch_CelebAToYearbook_cDCGAN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "dset = FolderWithImages(root='./yearbook/', input_transform=data_transforms['train'], target_transform=data_transforms['train']) #new to get indices??\n",
    "dset.image_filenames.sort()\n",
    "shuf = True #new\n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size=batch_size, shuffle=shuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "x,_,l = train_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "from torchvision.models.resnet import model_urls\n",
    "\n",
    "model_urls['resnet18'] = model_urls['resnet18'].replace('https://', 'http://')\n",
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 22])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot = torch.FloatTensor(64, 22)\n",
    "\n",
    "# In your for loop\n",
    "y_onehot.zero_()\n",
    "y_onehot.scatter_(1, y_gender_[0:64].view(64,-1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gender_[0:64].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 22])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_iter: 1 loss: 186.56092834472656 corrects: tensor(4)\n",
      "num_iter: 2 loss: 186.12747192382812 corrects: tensor(5)\n",
      "num_iter: 3 loss: 184.33776346842447 corrects: tensor(6)\n",
      "num_iter: 4 loss: 185.45802688598633 corrects: tensor(5)\n",
      "num_iter: 5 loss: 185.37782592773436 corrects: tensor(6)\n",
      "num_iter: 6 loss: 184.8303197224935 corrects: tensor(6)\n",
      "num_iter: 7 loss: 184.89770289829798 corrects: tensor(6)\n",
      "num_iter: 8 loss: 185.2759494781494 corrects: tensor(6)\n",
      "num_iter: 9 loss: 184.80131022135416 corrects: tensor(6)\n",
      "num_iter: 10 loss: 185.07306671142578 corrects: tensor(5)\n",
      "num_iter: 11 loss: 184.75882651589134 corrects: tensor(5)\n",
      "num_iter: 12 loss: 184.68956883748373 corrects: tensor(5)\n",
      "num_iter: 13 loss: 184.74062758225662 corrects: tensor(5)\n",
      "num_iter: 14 loss: 185.0287628173828 corrects: tensor(5)\n",
      "num_iter: 15 loss: 185.35140380859374 corrects: tensor(5)\n",
      "num_iter: 16 loss: 185.2130069732666 corrects: tensor(5)\n",
      "num_iter: 17 loss: 185.10089739631204 corrects: tensor(5)\n",
      "num_iter: 18 loss: 185.02256605360242 corrects: tensor(5)\n",
      "num_iter: 19 loss: 184.95004995245682 corrects: tensor(5)\n",
      "num_iter: 20 loss: 184.85647735595703 corrects: tensor(5)\n",
      "num_iter: 21 loss: 184.71771821521577 corrects: tensor(5)\n",
      "num_iter: 22 loss: 184.19391077215022 corrects: tensor(5)\n",
      "num_iter: 23 loss: 183.99672931173572 corrects: tensor(5)\n",
      "num_iter: 24 loss: 183.76306597391763 corrects: tensor(5)\n",
      "num_iter: 25 loss: 183.20835021972655 corrects: tensor(6)\n",
      "num_iter: 26 loss: 183.16898404634915 corrects: tensor(6)\n",
      "num_iter: 27 loss: 183.02333860044126 corrects: tensor(6)\n",
      "num_iter: 28 loss: 182.96607862200057 corrects: tensor(6)\n",
      "num_iter: 29 loss: 182.96686843345904 corrects: tensor(6)\n",
      "num_iter: 30 loss: 182.9515177408854 corrects: tensor(6)\n",
      "num_iter: 31 loss: 183.0109390751008 corrects: tensor(6)\n",
      "num_iter: 32 loss: 182.82921266555786 corrects: tensor(6)\n",
      "num_iter: 33 loss: 182.7279279304273 corrects: tensor(6)\n",
      "num_iter: 34 loss: 182.46682873894187 corrects: tensor(6)\n",
      "num_iter: 35 loss: 182.79563816615513 corrects: tensor(6)\n",
      "num_iter: 36 loss: 182.94911744859485 corrects: tensor(6)\n",
      "num_iter: 37 loss: 182.9747483537004 corrects: tensor(6)\n",
      "num_iter: 38 loss: 182.8896343833522 corrects: tensor(6)\n",
      "num_iter: 39 loss: 182.6262406569261 corrects: tensor(6)\n",
      "num_iter: 40 loss: 182.60531349182128 corrects: tensor(6)\n",
      "num_iter: 41 loss: 182.54710127667684 corrects: tensor(6)\n",
      "num_iter: 42 loss: 182.48735990978423 corrects: tensor(6)\n",
      "num_iter: 43 loss: 182.55923710312953 corrects: tensor(6)\n",
      "num_iter: 44 loss: 182.47002827037466 corrects: tensor(6)\n",
      "num_iter: 45 loss: 182.53810696072048 corrects: tensor(6)\n",
      "num_iter: 46 loss: 182.44732433816662 corrects: tensor(6)\n",
      "num_iter: 47 loss: 182.4150747745595 corrects: tensor(6)\n",
      "num_iter: 48 loss: 182.1453857421875 corrects: tensor(6)\n",
      "num_iter: 49 loss: 181.9849180883291 corrects: tensor(6)\n",
      "num_iter: 50 loss: 181.91841522216797 corrects: tensor(6)\n",
      "num_iter: 51 loss: 182.0503459257238 corrects: tensor(6)\n",
      "num_iter: 52 loss: 181.98391224787787 corrects: tensor(6)\n",
      "num_iter: 53 loss: 181.87503454820165 corrects: tensor(6)\n",
      "num_iter: 54 loss: 181.7802813494647 corrects: tensor(6)\n",
      "num_iter: 55 loss: 181.80828191583808 corrects: tensor(6)\n",
      "num_iter: 56 loss: 181.68510001046317 corrects: tensor(6)\n",
      "num_iter: 57 loss: 181.64118288274398 corrects: tensor(6)\n",
      "num_iter: 58 loss: 181.60673996497846 corrects: tensor(6)\n",
      "num_iter: 59 loss: 181.49219965530654 corrects: tensor(6)\n",
      "num_iter: 60 loss: 181.3104446411133 corrects: tensor(6)\n",
      "num_iter: 61 loss: 181.2935480836962 corrects: tensor(6)\n",
      "num_iter: 62 loss: 181.35382547686177 corrects: tensor(6)\n",
      "num_iter: 63 loss: 181.32499065096417 corrects: tensor(6)\n",
      "num_iter: 64 loss: 181.3467104434967 corrects: tensor(6)\n",
      "num_iter: 65 loss: 181.3728717510517 corrects: tensor(6)\n",
      "num_iter: 66 loss: 181.27194491299716 corrects: tensor(6)\n",
      "num_iter: 67 loss: 181.1884451339494 corrects: tensor(6)\n",
      "num_iter: 68 loss: 181.25164839800667 corrects: tensor(6)\n",
      "num_iter: 69 loss: 181.23195504451144 corrects: tensor(6)\n",
      "num_iter: 70 loss: 181.2593551635742 corrects: tensor(6)\n",
      "num_iter: 71 loss: 181.22168720943827 corrects: tensor(6)\n",
      "num_iter: 72 loss: 181.20434867011176 corrects: tensor(6)\n",
      "num_iter: 73 loss: 181.2812207365689 corrects: tensor(6)\n",
      "num_iter: 74 loss: 181.1983603400153 corrects: tensor(6)\n",
      "num_iter: 75 loss: 181.0865028889974 corrects: tensor(6)\n",
      "num_iter: 76 loss: 181.0497663397538 corrects: tensor(6)\n",
      "num_iter: 77 loss: 181.0073382885425 corrects: tensor(6)\n",
      "num_iter: 78 loss: 180.90106611985428 corrects: tensor(6)\n",
      "num_iter: 79 loss: 180.99112498609327 corrects: tensor(6)\n",
      "num_iter: 80 loss: 181.04796409606934 corrects: tensor(6)\n",
      "num_iter: 81 loss: 180.9331706482687 corrects: tensor(6)\n",
      "num_iter: 82 loss: 180.8621800120284 corrects: tensor(6)\n",
      "num_iter: 83 loss: 180.79241759518544 corrects: tensor(6)\n",
      "num_iter: 84 loss: 180.75311915079752 corrects: tensor(6)\n",
      "num_iter: 85 loss: 180.68746194278492 corrects: tensor(6)\n",
      "num_iter: 86 loss: 180.5918163920558 corrects: tensor(6)\n",
      "num_iter: 87 loss: 180.5370320287244 corrects: tensor(6)\n",
      "num_iter: 88 loss: 180.67751624367455 corrects: tensor(6)\n",
      "num_iter: 89 loss: 180.66130185930916 corrects: tensor(6)\n",
      "num_iter: 90 loss: 180.6066670735677 corrects: tensor(6)\n",
      "num_iter: 91 loss: 180.58278379335508 corrects: tensor(6)\n",
      "num_iter: 92 loss: 180.54896595167077 corrects: tensor(6)\n",
      "num_iter: 93 loss: 180.45674691148983 corrects: tensor(6)\n",
      "num_iter: 94 loss: 180.41327829563872 corrects: tensor(7)\n",
      "num_iter: 95 loss: 180.47583329050164 corrects: tensor(7)\n",
      "num_iter: 96 loss: 180.45943387349448 corrects: tensor(7)\n",
      "num_iter: 97 loss: 180.42344712719475 corrects: tensor(7)\n",
      "num_iter: 98 loss: 180.41793698680644 corrects: tensor(7)\n",
      "num_iter: 99 loss: 180.4771394055299 corrects: tensor(6)\n",
      "num_iter: 100 loss: 180.41803695678712 corrects: tensor(7)\n",
      "num_iter: 101 loss: 180.40292569906404 corrects: tensor(7)\n",
      "num_iter: 102 loss: 180.31069198309206 corrects: tensor(7)\n",
      "num_iter: 103 loss: 180.3522150724837 corrects: tensor(7)\n",
      "num_iter: 104 loss: 180.31413973294772 corrects: tensor(7)\n",
      "num_iter: 105 loss: 180.25237804594494 corrects: tensor(7)\n",
      "num_iter: 106 loss: 180.21319623263378 corrects: tensor(7)\n",
      "num_iter: 107 loss: 180.23061620409243 corrects: tensor(7)\n",
      "num_iter: 108 loss: 180.09059072423864 corrects: tensor(7)\n",
      "num_iter: 109 loss: 180.09503117832568 corrects: tensor(7)\n",
      "num_iter: 110 loss: 180.06433230313388 corrects: tensor(7)\n",
      "num_iter: 111 loss: 180.02391354672542 corrects: tensor(7)\n",
      "num_iter: 112 loss: 179.9522135598319 corrects: tensor(7)\n",
      "num_iter: 113 loss: 179.93215145684977 corrects: tensor(7)\n",
      "num_iter: 114 loss: 179.82045759234512 corrects: tensor(7)\n",
      "num_iter: 115 loss: 179.72765383513078 corrects: tensor(7)\n",
      "num_iter: 116 loss: 179.63295140759698 corrects: tensor(7)\n",
      "num_iter: 117 loss: 179.5592539208567 corrects: tensor(7)\n",
      "num_iter: 118 loss: 179.49860847602457 corrects: tensor(7)\n",
      "num_iter: 119 loss: 179.44573807916723 corrects: tensor(7)\n",
      "num_iter: 120 loss: 179.45628000895184 corrects: tensor(7)\n",
      "num_iter: 121 loss: 179.46998974508492 corrects: tensor(7)\n",
      "num_iter: 122 loss: 179.37331715568166 corrects: tensor(7)\n",
      "num_iter: 123 loss: 179.32985867135892 corrects: tensor(7)\n",
      "num_iter: 124 loss: 179.29404240269815 corrects: tensor(7)\n",
      "num_iter: 125 loss: 179.19676977539064 corrects: tensor(7)\n",
      "num_iter: 126 loss: 179.14989120241196 corrects: tensor(7)\n",
      "num_iter: 127 loss: 179.1366358479177 corrects: tensor(7)\n",
      "num_iter: 128 loss: 179.05062448978424 corrects: tensor(7)\n",
      "num_iter: 129 loss: 178.9942863523498 corrects: tensor(7)\n",
      "num_iter: 130 loss: 178.98114776611328 corrects: tensor(7)\n",
      "num_iter: 131 loss: 178.99874458604185 corrects: tensor(7)\n",
      "num_iter: 132 loss: 178.96140659216678 corrects: tensor(7)\n",
      "num_iter: 133 loss: 178.88428973434563 corrects: tensor(7)\n",
      "num_iter: 134 loss: 178.8417294630364 corrects: tensor(7)\n",
      "num_iter: 135 loss: 178.79879331235531 corrects: tensor(7)\n",
      "num_iter: 136 loss: 178.73841813031365 corrects: tensor(7)\n",
      "num_iter: 137 loss: 178.68496804341783 corrects: tensor(7)\n",
      "num_iter: 138 loss: 178.6878564806952 corrects: tensor(7)\n",
      "num_iter: 139 loss: 178.58523219266382 corrects: tensor(7)\n",
      "num_iter: 140 loss: 178.54240733555386 corrects: tensor(7)\n",
      "num_iter: 141 loss: 178.6363022175241 corrects: tensor(7)\n",
      "num_iter: 142 loss: 178.58272004463302 corrects: tensor(7)\n",
      "num_iter: 143 loss: 178.49714383212003 corrects: tensor(7)\n",
      "num_iter: 144 loss: 178.50133344862195 corrects: tensor(7)\n",
      "num_iter: 145 loss: 178.44579109981143 corrects: tensor(7)\n",
      "num_iter: 146 loss: 178.4465209751913 corrects: tensor(7)\n",
      "num_iter: 147 loss: 178.40472069565132 corrects: tensor(7)\n",
      "num_iter: 148 loss: 178.35950036951013 corrects: tensor(7)\n",
      "num_iter: 149 loss: 178.34194280637192 corrects: tensor(7)\n",
      "num_iter: 150 loss: 178.30406860351562 corrects: tensor(7)\n",
      "num_iter: 151 loss: 178.2919915811905 corrects: tensor(7)\n",
      "num_iter: 152 loss: 178.28597319753547 corrects: tensor(7)\n",
      "num_iter: 153 loss: 178.23766910328584 corrects: tensor(7)\n",
      "num_iter: 154 loss: 178.19850099241577 corrects: tensor(7)\n",
      "num_iter: 155 loss: 178.13476345923638 corrects: tensor(7)\n",
      "num_iter: 156 loss: 178.1097666422526 corrects: tensor(7)\n",
      "num_iter: 157 loss: 178.07476116593477 corrects: tensor(7)\n",
      "num_iter: 158 loss: 178.04921297483807 corrects: tensor(7)\n",
      "num_iter: 159 loss: 178.0115919772934 corrects: tensor(7)\n",
      "num_iter: 160 loss: 177.99676218032837 corrects: tensor(7)\n",
      "num_iter: 161 loss: 177.92181965134898 corrects: tensor(7)\n",
      "num_iter: 162 loss: 177.9283184475369 corrects: tensor(7)\n",
      "num_iter: 163 loss: 177.89479046218966 corrects: tensor(7)\n",
      "num_iter: 164 loss: 177.7944558306438 corrects: tensor(8)\n",
      "num_iter: 165 loss: 177.7412851044626 corrects: tensor(8)\n",
      "num_iter: 166 loss: 177.69271446136108 corrects: tensor(8)\n",
      "num_iter: 167 loss: 177.70684933234116 corrects: tensor(8)\n",
      "num_iter: 168 loss: 177.6488183339437 corrects: tensor(8)\n",
      "num_iter: 169 loss: 177.62396456927237 corrects: tensor(8)\n",
      "num_iter: 170 loss: 177.66063331155215 corrects: tensor(8)\n",
      "num_iter: 171 loss: 177.64246444255986 corrects: tensor(8)\n",
      "num_iter: 172 loss: 177.59496298501656 corrects: tensor(8)\n",
      "num_iter: 173 loss: 177.5318063724937 corrects: tensor(8)\n",
      "num_iter: 174 loss: 177.46632297559717 corrects: tensor(8)\n",
      "num_iter: 175 loss: 177.43790588378906 corrects: tensor(8)\n",
      "num_iter: 176 loss: 177.43815690820867 corrects: tensor(8)\n",
      "num_iter: 177 loss: 177.39342572055966 corrects: tensor(8)\n",
      "num_iter: 178 loss: 177.35375025031271 corrects: tensor(8)\n",
      "num_iter: 179 loss: 177.2882203682841 corrects: tensor(8)\n",
      "num_iter: 180 loss: 177.24402287801107 corrects: tensor(8)\n",
      "num_iter: 181 loss: 177.20921688185211 corrects: tensor(8)\n",
      "num_iter: 182 loss: 177.17483595963364 corrects: tensor(8)\n",
      "num_iter: 183 loss: 177.1327727270908 corrects: tensor(8)\n",
      "num_iter: 184 loss: 177.09076599452806 corrects: tensor(8)\n",
      "num_iter: 185 loss: 177.09059266786318 corrects: tensor(8)\n",
      "num_iter: 186 loss: 177.09254365326257 corrects: tensor(8)\n",
      "num_iter: 187 loss: 177.0406791156626 corrects: tensor(8)\n",
      "num_iter: 188 loss: 177.05030903917677 corrects: tensor(8)\n",
      "num_iter: 189 loss: 176.98726924512752 corrects: tensor(8)\n",
      "num_iter: 190 loss: 176.98184950979132 corrects: tensor(8)\n",
      "num_iter: 191 loss: 176.98363235233967 corrects: tensor(8)\n",
      "num_iter: 192 loss: 176.94312151273093 corrects: tensor(8)\n",
      "num_iter: 193 loss: 176.89309929566062 corrects: tensor(8)\n",
      "num_iter: 194 loss: 176.9073362055513 corrects: tensor(8)\n",
      "num_iter: 195 loss: 176.8762649144882 corrects: tensor(8)\n",
      "num_iter: 196 loss: 176.83817384680924 corrects: tensor(8)\n",
      "num_iter: 197 loss: 176.80554601988817 corrects: tensor(8)\n",
      "num_iter: 198 loss: 176.7574068319918 corrects: tensor(8)\n",
      "num_iter: 199 loss: 176.74529139839825 corrects: tensor(8)\n",
      "num_iter: 200 loss: 176.7102700805664 corrects: tensor(8)\n",
      "num_iter: 201 loss: 176.69551397674712 corrects: tensor(8)\n",
      "num_iter: 202 loss: 176.6458524194094 corrects: tensor(8)\n",
      "num_iter: 203 loss: 176.60048889761487 corrects: tensor(8)\n",
      "num_iter: 204 loss: 176.53445434570312 corrects: tensor(8)\n",
      "num_iter: 205 loss: 176.48545026081365 corrects: tensor(8)\n",
      "num_iter: 206 loss: 176.48296437680142 corrects: tensor(8)\n",
      "num_iter: 207 loss: 176.43466960519984 corrects: tensor(8)\n",
      "num_iter: 208 loss: 176.39817076462967 corrects: tensor(8)\n",
      "num_iter: 209 loss: 176.3674301804538 corrects: tensor(8)\n",
      "num_iter: 210 loss: 176.30115727015905 corrects: tensor(8)\n"
     ]
    }
   ],
   "source": [
    "model = model_conv\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "max_epoch = 30\n",
    "bsize = 64\n",
    "\n",
    "num_iter = 0\n",
    "running_loss = 0.0\n",
    "running_corrects = 0.0\n",
    "for epoch in range(max_epoch):\n",
    "    exp_lr_scheduler.step()\n",
    "    while num_iter < len(train_loader):\n",
    "        inputs,_,label_ids = train_iter.next()\n",
    "        labels = y_gender_[label_ids]\n",
    "        labels_onehot = torch.FloatTensor(bsize, num_classes)\n",
    "        labels_onehot.zero_()\n",
    "        labels_onehot.scatter_(1, labels.view(bsize,-1), 1)\n",
    "        inputs,labels = Variable(inputs),Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        num_iter += 1\n",
    "        print('num_iter: ' + str(num_iter) + ' loss: ' + str(running_loss/num_iter) + ' corrects: ' + str(running_corrects/num_iter))\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = running_corrects.double() / len(train_loader)\n",
    "    \n",
    "    print('Epoch: ' + str(epoch) + ' ' + str(epoch_loss) + ' ' + str(epoch_acc))\n",
    "\n",
    "\n",
    "#for epoch in range(max_epoch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AlexNet' object has no attribute 'fc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b54be51ae9aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Parameters of newly constructed modules have requires_grad=True by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnum_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 532\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AlexNet' object has no attribute 'fc'"
     ]
    }
   ],
   "source": [
    "import torchvision.models\n",
    "from torchvision.models.alexnet import model_urls\n",
    "\n",
    "model_urls['alexnet'] = model_urls['alexnet'].replace('https://', 'http://')\n",
    "model_conv = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "\n",
    "\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "unexpected EOF. The file might be corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fda9b5540cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_res18_12.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_is_real_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unexpected EOF. The file might be corrupted."
     ]
    }
   ],
   "source": [
    "mod = torch.load('model_res18_12.pth',map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_conv.load_state_dict(torch.load('model_test(1).pth',map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_conv = model_conv.eval()\n",
    "outputs = model_conv(x)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "labels = y_gender_[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(34)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(preds == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0f835d7d074a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRandomly\u001b[0m \u001b[0mcropped\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresized\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresized_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(img, scale, ratio)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \"\"\"\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m             \u001b[0mtarget_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0maspect_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data_transforms['train'](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5a529e12840d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mttr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRandomly\u001b[0m \u001b[0mcropped\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresized\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresized_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(img, scale, ratio)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \"\"\"\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m             \u001b[0mtarget_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0maspect_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "ttr(x[1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = transforms.ToPILImage()(x[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = data_transforms['train'](y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
